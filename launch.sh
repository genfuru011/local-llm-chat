#!/bin/bash

# Local LLM Chat - ç°¡å˜èµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
# éžã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢å‘ã‘ã®æœ€ã‚‚ç°¡å˜ãªèµ·å‹•æ–¹æ³•

set -e

echo "ðŸš€ Local LLM Chat ã‚’èµ·å‹•ä¸­..."

# è‰²ä»˜ããƒ¡ãƒƒã‚»ãƒ¼ã‚¸é–¢æ•°
print_success() { echo -e "\033[32mâœ… $1\033[0m"; }
print_error() { echo -e "\033[31mâŒ $1\033[0m"; }
print_warning() { echo -e "\033[33mâš ï¸  $1\033[0m"; }
print_info() { echo -e "\033[34mâ„¹ï¸  $1\033[0m"; }

# Ollamaã®ç¢ºèªã¨ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
check_and_install_ollama() {
    if ! command -v ollama &> /dev/null; then
        print_error "OllamaãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“"
        print_info "Ollamaã‚’è‡ªå‹•ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã‹ï¼Ÿ (y/n)"
        read -r response
        if [[ "$response" =~ ^[Yy]$ ]]; then
            print_info "Ollamaã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­..."
            if command -v curl &> /dev/null; then
                curl -fsSL https://ollama.ai/install.sh | sh
            else
                print_warning "curlãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ‰‹å‹•ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒšãƒ¼ã‚¸ã‚’é–‹ãã¾ã™..."
                open "https://ollama.ai/download"
                exit 1
            fi
        else
            print_error "OllamaãŒå¿…è¦ã§ã™ã€‚https://ollama.ai/download ã‹ã‚‰ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„"
            exit 1
        fi
    fi
    print_success "Ollama ãŒåˆ©ç”¨å¯èƒ½ã§ã™"
}

# Node.jsã®ç¢ºèªã¨ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
check_and_install_nodejs() {
    if ! command -v node &> /dev/null; then
        print_error "Node.jsãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“"
        print_info "Node.jsã‚’è‡ªå‹•ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã‹ï¼Ÿ (y/n)"
        read -r response
        if [[ "$response" =~ ^[Yy]$ ]]; then
            print_info "Node.jsã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒšãƒ¼ã‚¸ã‚’é–‹ãã¾ã™..."
            open "https://nodejs.org/ja/download/"
            print_warning "Node.jsã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å¾Œã€ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å†å®Ÿè¡Œã—ã¦ãã ã•ã„"
            exit 1
        else
            print_error "Node.jsãŒå¿…è¦ã§ã™ã€‚https://nodejs.org/ja/download/ ã‹ã‚‰ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„"
            exit 1
        fi
    fi
    print_success "Node.js ãŒåˆ©ç”¨å¯èƒ½ã§ã™ ($(node --version))"
}

# Ollamaã‚µãƒ¼ãƒ“ã‚¹ã®èµ·å‹•
start_ollama_service() {
    if ! pgrep -f "ollama serve" > /dev/null; then
        print_info "Ollama ã‚µãƒ¼ãƒ“ã‚¹ã‚’èµ·å‹•ä¸­..."
        ollama serve &
        sleep 3
        print_success "Ollama ã‚µãƒ¼ãƒ“ã‚¹ãŒèµ·å‹•ã—ã¾ã—ãŸ"
    else
        print_success "Ollama ã‚µãƒ¼ãƒ“ã‚¹ã¯æ—¢ã«å‹•ä½œä¸­ã§ã™"
    fi
}

# AIãƒ¢ãƒ‡ãƒ«ã®ç¢ºèªã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
setup_ai_model() {
    print_info "AIãƒ¢ãƒ‡ãƒ«ã‚’ç¢ºèªä¸­..."
    if ! ollama list | grep -q "llama3.2"; then
        print_warning "åŸºæœ¬AIãƒ¢ãƒ‡ãƒ«ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“"
        print_info "Llama 3.2ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã‹ï¼Ÿ (ç´„2GB) (y/n)"
        read -r response
        if [[ "$response" =~ ^[Yy]$ ]]; then
            print_info "AIãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­... (æ•°åˆ†ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™)"
            ollama pull llama3.2
            print_success "AIãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒå®Œäº†ã—ã¾ã—ãŸ"
        else
            print_warning "AIãƒ¢ãƒ‡ãƒ«ãŒãªã„ã¨ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ã¯ä½¿ç”¨ã§ãã¾ã›ã‚“"
        fi
    else
        print_success "AIãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨å¯èƒ½ã§ã™"
    fi
}

# ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
install_dependencies() {
    if [ ! -d "node_modules" ]; then
        print_info "å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­..."
        npm install
        print_success "ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒå®Œäº†ã—ã¾ã—ãŸ"
    else
        print_success "ä¾å­˜é–¢ä¿‚ã¯æ—¢ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ã§ã™"
    fi
}

# ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®èµ·å‹•
start_application() {
    print_info "Local LLM Chat ã‚’èµ·å‹•ä¸­..."
    
    # ãƒãƒ¼ãƒˆã®ç¢ºèª
    if lsof -i :3000 > /dev/null 2>&1; then
        print_warning "ãƒãƒ¼ãƒˆ3000ã¯æ—¢ã«ä½¿ç”¨ä¸­ã§ã™"
        print_info "å®Ÿè¡Œä¸­ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’åœæ­¢ã—ã¦ã‹ã‚‰å†å®Ÿè¡Œã—ã¦ãã ã•ã„"
        exit 1
    fi
    
    # Next.jsã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•
    npm run dev &
    SERVER_PID=$!
    
    # ã‚µãƒ¼ãƒãƒ¼ã®èµ·å‹•ã‚’å¾…æ©Ÿ
    print_info "ã‚µãƒ¼ãƒãƒ¼ã®èµ·å‹•ã‚’å¾…æ©Ÿä¸­..."
    sleep 8
    
    # ãƒ–ãƒ©ã‚¦ã‚¶ã§ã‚¢ãƒ—ãƒªã‚’é–‹ã
    print_success "ãƒ–ãƒ©ã‚¦ã‚¶ã§Local LLM Chatã‚’é–‹ã„ã¦ã„ã¾ã™..."
    open "http://localhost:3000"
    
    print_success "ðŸŽ‰ Local LLM Chat ãŒèµ·å‹•ã—ã¾ã—ãŸï¼"
    print_info "ðŸ“± ãƒ–ãƒ©ã‚¦ã‚¶ã§ http://localhost:3000 ã‚’é–‹ã„ã¦ãã ã•ã„"
    print_info "ðŸ›‘ çµ‚äº†ã™ã‚‹ã«ã¯ Ctrl+C ã‚’æŠ¼ã—ã¦ãã ã•ã„"
    
    # ã‚¢ãƒ—ãƒªã®çµ‚äº†ã‚’ç›£è¦–
    wait $SERVER_PID
}

# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œãƒ•ãƒ­ãƒ¼
main() {
    echo "========================="
    echo "  Local LLM Chat èµ·å‹•"
    echo "========================="
    echo ""
    
    check_and_install_ollama
    check_and_install_nodejs
    start_ollama_service
    setup_ai_model
    install_dependencies
    start_application
}

# ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
trap 'print_error "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’çµ‚äº†ã—ã¾ã™ã€‚"' ERR

# Ctrl+Cã§ã®çµ‚äº†å‡¦ç†
trap 'print_info "ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’çµ‚äº†ã—ã¦ã„ã¾ã™..."; kill $SERVER_PID 2>/dev/null; exit 0' INT

main "$@"
